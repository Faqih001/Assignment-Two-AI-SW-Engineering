{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b070de0c",
   "metadata": {},
   "source": [
    "# AI Tools Assignment: Mastering the AI Toolkit üõ†Ô∏èüß†\n",
    "\n",
    "This notebook contains the implementation of various AI tasks using different frameworks and tools. The assignment is divided into three main parts:\n",
    "1. Theoretical Understanding\n",
    "2. Practical Implementation\n",
    "3. Ethics & Optimization\n",
    "\n",
    "## Setup\n",
    "First, let's install and import all the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225cc037",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.18' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: '/usr/bin/python3.10 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip install tensorflow torch scikit-learn spacy pandas numpy matplotlib seaborn streamlit flask tensorflow-model-analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a474e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829d5f29",
   "metadata": {},
   "source": [
    "# Part 1: Theoretical Understanding\n",
    "\n",
    "## Short Answer Questions\n",
    "\n",
    "### Q1: TensorFlow vs PyTorch\n",
    "Explain the primary differences between TensorFlow and PyTorch, and when you would choose one over the other.\n",
    "\n",
    "[Your answer here]\n",
    "\n",
    "### Q2: Jupyter Notebooks Use Cases\n",
    "Describe two use cases for Jupyter Notebooks in AI development.\n",
    "\n",
    "[Your answer here]\n",
    "\n",
    "### Q3: spaCy's NLP Capabilities\n",
    "How does spaCy enhance NLP tasks compared to basic Python string operations?\n",
    "\n",
    "[Your answer here]\n",
    "\n",
    "## Comparative Analysis\n",
    "\n",
    "Compare Scikit-learn and TensorFlow in terms of:\n",
    "\n",
    "| Feature | Scikit-learn | TensorFlow |\n",
    "|---------|--------------|------------|\n",
    "| Target applications | | |\n",
    "| Ease of use for beginners | | |\n",
    "| Community support | | |\n",
    "\n",
    "[Fill in the comparison table above with your analysis]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfe838b",
   "metadata": {},
   "source": [
    "# Part 2: Practical Implementation\n",
    "\n",
    "## Task 1: Classical ML with Scikit-learn - Iris Dataset\n",
    "\n",
    "In this task, we will:\n",
    "1. Load and preprocess the Iris dataset\n",
    "2. Handle any missing values\n",
    "3. Encode labels\n",
    "4. Train a decision tree classifier\n",
    "5. Evaluate the model using accuracy, precision, and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e93cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "y = iris.target\n",
    "\n",
    "# Check for missing values\n",
    "print(\"Missing values in the dataset:\")\n",
    "print(X.isnull().sum())\n",
    "\n",
    "# Create train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"\\nDataset shapes:\")\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be07c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Decision Tree Classifier\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(\"Model Performance Metrics:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "\n",
    "# Visualize feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': iris.feature_names,\n",
    "    'importance': clf.feature_importances_\n",
    "})\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=feature_importance, x='importance', y='feature')\n",
    "plt.title('Feature Importance in Iris Classification')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a65953b",
   "metadata": {},
   "source": [
    "## Task 2: Deep Learning with TensorFlow/PyTorch - MNIST Classification\n",
    "\n",
    "In this task, we will:\n",
    "1. Load and preprocess the MNIST dataset\n",
    "2. Build a CNN model\n",
    "3. Train the model to achieve >95% test accuracy\n",
    "4. Visualize predictions on sample images\n",
    "\n",
    "We'll use TensorFlow for this implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485798e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess MNIST dataset\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Normalize pixel values\n",
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0\n",
    "\n",
    "# Reshape for CNN (add channel dimension)\n",
    "X_train = X_train.reshape(-1, 28, 28, 1)\n",
    "X_test = X_test.reshape(-1, 28, 28, 1)\n",
    "\n",
    "print(\"Dataset shapes:\")\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df55f89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    batch_size=128)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"\\nTest accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3d5cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select 5 random test images\n",
    "n_samples = 5\n",
    "sample_indices = np.random.choice(len(X_test), n_samples, replace=False)\n",
    "sample_images = X_test[sample_indices]\n",
    "sample_labels = y_test[sample_indices]\n",
    "\n",
    "# Get predictions\n",
    "predictions = model.predict(sample_images)\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(15, 3))\n",
    "for i in range(n_samples):\n",
    "    plt.subplot(1, n_samples, i + 1)\n",
    "    plt.imshow(sample_images[i].reshape(28, 28), cmap='gray')\n",
    "    plt.title(f'True: {sample_labels[i]}\\nPred: {predicted_labels[i]}')\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb6b034",
   "metadata": {},
   "source": [
    "## Task 3: NLP with spaCy - Named Entity Recognition and Sentiment Analysis\n",
    "\n",
    "In this task, we will:\n",
    "1. Load and process Amazon product reviews\n",
    "2. Perform Named Entity Recognition (NER) to extract product names and brands\n",
    "3. Implement a rule-based sentiment analysis\n",
    "4. Display extracted entities and sentiment results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b96f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download spaCy English model\n",
    "!python -m spacy download en_core_web_sm\n",
    "\n",
    "# Sample Amazon reviews data\n",
    "reviews = [\n",
    "    \"The Apple iPhone 13 Pro has an amazing camera and great battery life. Highly recommend!\",\n",
    "    \"This Samsung TV is terrible. The picture quality is poor and customer service is awful.\",\n",
    "    \"Nike running shoes are comfortable and durable. Perfect for long distance running.\",\n",
    "    \"The Sony headphones have excellent sound quality but they're a bit expensive.\",\n",
    "    \"Dell laptop keeps crashing. Waste of money, very disappointed with the product.\"\n",
    "]\n",
    "\n",
    "# Load spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Function to extract entities\n",
    "def extract_entities(text):\n",
    "    doc = nlp(text)\n",
    "    entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "    return entities\n",
    "\n",
    "# Simple rule-based sentiment analysis\n",
    "def analyze_sentiment(text):\n",
    "    positive_words = ['amazing', 'great', 'excellent', 'good', 'perfect', 'comfortable', 'recommend']\n",
    "    negative_words = ['terrible', 'poor', 'awful', 'waste', 'disappointed', 'bad', 'crashes']\n",
    "    \n",
    "    text = text.lower()\n",
    "    positive_score = sum([1 for word in positive_words if word in text])\n",
    "    negative_score = sum([1 for word in negative_words if word in text])\n",
    "    \n",
    "    if positive_score > negative_score:\n",
    "        return 'Positive'\n",
    "    elif negative_score > positive_score:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "\n",
    "# Process reviews\n",
    "results = []\n",
    "for review in reviews:\n",
    "    entities = extract_entities(review)\n",
    "    sentiment = analyze_sentiment(review)\n",
    "    results.append({\n",
    "        'review': review,\n",
    "        'entities': entities,\n",
    "        'sentiment': sentiment\n",
    "    })\n",
    "\n",
    "# Display results\n",
    "for result in results:\n",
    "    print(f\"\\nReview: {result['review']}\")\n",
    "    print(f\"Entities: {result['entities']}\")\n",
    "    print(f\"Sentiment: {result['sentiment']}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1244ce68",
   "metadata": {},
   "source": [
    "# Part 3: Ethics & Optimization\n",
    "\n",
    "## Ethical Considerations in AI Models\n",
    "\n",
    "### MNIST Model Bias Analysis\n",
    "1. Potential biases in the MNIST dataset:\n",
    "   - Limited handwriting styles and variations\n",
    "   - Possible underrepresentation of different cultural writing styles\n",
    "   - Bias towards certain digit writing conventions\n",
    "\n",
    "2. Mitigating biases:\n",
    "   - Data augmentation to increase variation\n",
    "   - Using TensorFlow Fairness Indicators for model evaluation\n",
    "   - Regular model monitoring and retraining\n",
    "\n",
    "### Amazon Reviews Model Bias Analysis\n",
    "1. Potential biases in sentiment analysis:\n",
    "   - Language and cultural biases in sentiment words\n",
    "   - Context-dependent interpretations\n",
    "   - Brand name recognition limitations\n",
    "\n",
    "2. Mitigating biases:\n",
    "   - Using multilingual models\n",
    "   - Implementing context-aware analysis\n",
    "   - Regular updates to sentiment dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ca2739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of using TensorFlow Fairness Indicators for MNIST\n",
    "import tensorflow_model_analysis as tfma\n",
    "\n",
    "# Function to create a simple fairness evaluation\n",
    "def evaluate_model_fairness(model, test_data, test_labels):\n",
    "    predictions = model.predict(test_data)\n",
    "    predicted_labels = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    # Calculate accuracy per class\n",
    "    class_accuracies = []\n",
    "    for digit in range(10):\n",
    "        mask = test_labels == digit\n",
    "        class_acc = accuracy_score(test_labels[mask], predicted_labels[mask])\n",
    "        class_accuracies.append(class_acc)\n",
    "        print(f\"Accuracy for digit {digit}: {class_acc:.4f}\")\n",
    "    \n",
    "    # Calculate fairness metrics\n",
    "    min_acc = min(class_accuracies)\n",
    "    max_acc = max(class_accuracies)\n",
    "    acc_disparity = max_acc - min_acc\n",
    "    \n",
    "    print(f\"\\nFairness Metrics:\")\n",
    "    print(f\"Minimum class accuracy: {min_acc:.4f}\")\n",
    "    print(f\"Maximum class accuracy: {max_acc:.4f}\")\n",
    "    print(f\"Accuracy disparity: {acc_disparity:.4f}\")\n",
    "    \n",
    "    return class_accuracies\n",
    "\n",
    "# Evaluate fairness on MNIST model\n",
    "class_accuracies = evaluate_model_fairness(model, X_test, y_test)\n",
    "\n",
    "# Visualize class-wise accuracies\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(10), class_accuracies)\n",
    "plt.title('Accuracy Distribution Across Digits')\n",
    "plt.xlabel('Digit')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89be5d89",
   "metadata": {},
   "source": [
    "# Bonus Task: Deploy MNIST Classifier with Streamlit\n",
    "\n",
    "In this section, we'll create a simple web interface for our MNIST classifier using Streamlit. This will allow users to draw digits and get real-time predictions from our model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
